{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b14f340-f124-4cfa-ba29-efd27e7eb5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585e165-51fc-4370-9740-6d1612018f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d6cd563-38f3-4df2-af3b-b4c400edb6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_url = \"https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cffd52c5-7278-420f-aeca-d2314eee8d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(train_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8741364a-3b61-46c2-ae4a-ea79e8495771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17366</td>\n",
       "      <td>Merkel: Strong result for Austria's FPO 'big c...</td>\n",
       "      <td>German Chancellor Angela Merkel said on Monday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5634</td>\n",
       "      <td>Trump says Pence will lead voter fraud panel</td>\n",
       "      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17487</td>\n",
       "      <td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>\n",
       "      <td>On December 5, 2017, Circa s Sara Carter warne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12217</td>\n",
       "      <td>Thyssenkrupp has offered help to Argentina ove...</td>\n",
       "      <td>Germany s Thyssenkrupp, has offered assistance...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5535</td>\n",
       "      <td>Trump say appeals court decision on travel ban...</td>\n",
       "      <td>President Donald Trump on Thursday called the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22444</th>\n",
       "      <td>10709</td>\n",
       "      <td>ALARMING: NSA Refuses to Release Clinton-Lynch...</td>\n",
       "      <td>If Clinton and Lynch just talked about grandki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22445</th>\n",
       "      <td>8731</td>\n",
       "      <td>Can Pence's vow not to sling mud survive a Tru...</td>\n",
       "      <td>() - In 1990, during a close and bitter congre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22446</th>\n",
       "      <td>4733</td>\n",
       "      <td>Watch Trump Campaign Try To Spin Their Way Ou...</td>\n",
       "      <td>A new ad by the Hillary Clinton SuperPac Prior...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22447</th>\n",
       "      <td>3993</td>\n",
       "      <td>Trump celebrates first 100 days as president, ...</td>\n",
       "      <td>HARRISBURG, Pa.U.S. President Donald Trump hit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22448</th>\n",
       "      <td>12896</td>\n",
       "      <td>TRUMP SUPPORTERS REACT TO DEBATE: “Clinton New...</td>\n",
       "      <td>MELBOURNE, FL is a town with a population of 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22449 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0           17366  Merkel: Strong result for Austria's FPO 'big c...   \n",
       "1            5634       Trump says Pence will lead voter fraud panel   \n",
       "2           17487  JUST IN: SUSPECTED LEAKER and “Close Confidant...   \n",
       "3           12217  Thyssenkrupp has offered help to Argentina ove...   \n",
       "4            5535  Trump say appeals court decision on travel ban...   \n",
       "...           ...                                                ...   \n",
       "22444       10709  ALARMING: NSA Refuses to Release Clinton-Lynch...   \n",
       "22445        8731  Can Pence's vow not to sling mud survive a Tru...   \n",
       "22446        4733   Watch Trump Campaign Try To Spin Their Way Ou...   \n",
       "22447        3993  Trump celebrates first 100 days as president, ...   \n",
       "22448       12896  TRUMP SUPPORTERS REACT TO DEBATE: “Clinton New...   \n",
       "\n",
       "                                                    text  fake  \n",
       "0      German Chancellor Angela Merkel said on Monday...     0  \n",
       "1      WEST PALM BEACH, Fla.President Donald Trump sa...     0  \n",
       "2      On December 5, 2017, Circa s Sara Carter warne...     1  \n",
       "3      Germany s Thyssenkrupp, has offered assistance...     0  \n",
       "4      President Donald Trump on Thursday called the ...     0  \n",
       "...                                                  ...   ...  \n",
       "22444  If Clinton and Lynch just talked about grandki...     1  \n",
       "22445  () - In 1990, during a close and bitter congre...     0  \n",
       "22446  A new ad by the Hillary Clinton SuperPac Prior...     1  \n",
       "22447  HARRISBURG, Pa.U.S. President Donald Trump hit...     0  \n",
       "22448  MELBOURNE, FL is a town with a population of 7...     1  \n",
       "\n",
       "[22449 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7125ae2a-b74c-462a-8ff2-bd321dd8b360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cake\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc09bc-dc91-40db-a1ac-11d9c468da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf081e1f-9b93-48dd-86a3-5d7081b78180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df):\n",
    "    #\n",
    "    df[\"title\"] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    #\n",
    "    df[\"text\"] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    \n",
    "    data = tf.data.Dataset.from_tensor_slices(( \n",
    "    #input dictionary\n",
    "    { \"title\": df[[\"title\"]],\n",
    "     \"text\": df[\"text\"]},\n",
    "\n",
    "    #output dictionary\n",
    "    { \"fake\": df[[\"fake\"]]}\n",
    "    ))\n",
    "    return data.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc8bdffa-03d0-4110-ae65-72100b499788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74127222-3741-4af8-82d6-48bef6d01bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c45d5-1bb9-468f-867d-1164c66008f8",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "20% of the dataset is reserved for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9b8c6ac-6a73-46ca-b306-6489038f2cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 45\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size = dataset_size)\n",
    "\n",
    "val_size  = int(dataset_size * 0.2)\n",
    "\n",
    "val = dataset.take(val_size)\n",
    "train = dataset.skip(val_size).take(dataset_size - val_size)\n",
    "\n",
    "#check size of training and validation sets\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9239ed45-bf2d-46e1-9c8a-2279ed2fa63e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389 fake and 8560 real\n",
      "total sample is 17949\n",
      "Our base rate of fake articles is 52.30932085352944%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels_iterator= train.unbatch().map(lambda input, output: output).as_numpy_iterator()\n",
    "fake = 0\n",
    "real = 0\n",
    "for i in labels_iterator:\n",
    "    if i['fake'] == 1:\n",
    "        fake +=1\n",
    "    else:\n",
    "        real +=1\n",
    "print(f\"{fake} fake and {real} real\")\n",
    "print(f\"total sample is {real + fake}\")\n",
    "print(f\"Our base rate of fake articles is {fake*100/(fake+real)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6e5f9a5-6521-4ac8-8087-532a2fb64ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f731a94b-8936-4b94-887a-dda006b207b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preparing a text vectorization layer for tf model\n",
    "size_vocabulary = 2000\n",
    "\n",
    "def standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    no_punctuation = tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation),'')\n",
    "    return no_punctuation\n",
    "\n",
    "title_vectorize_layer = TextVectorization(\n",
    "    standardize=standardization,\n",
    "    max_tokens=size_vocabulary, # only consider this many words\n",
    "    output_mode='int',\n",
    "    output_sequence_length=500) \n",
    "\n",
    "title_vectorize_layer.adapt(train.map(lambda x, y: x[\"title\"]))\n",
    "\n",
    "\n",
    "text_vectorize_layer = TextVectorization(\n",
    "    standardize=standardization,\n",
    "    max_tokens=size_vocabulary, # only consider this many words\n",
    "    output_mode='int',\n",
    "    output_sequence_length=500) \n",
    "\n",
    "text_vectorize_layer.adapt(train.map(lambda x, y: x[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf000183-784f-4041-8494-ac80fd3ecfc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# inputs\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m title_input \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mInput(\n\u001b[0;32m      4\u001b[0m     shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(scalars),),\n\u001b[0;32m      5\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# inputs\n",
    "\n",
    "title_input = keras.Input(\n",
    "    shape = (len(scalars),),\n",
    "    name = \"title\",\n",
    "    dtype = \"string\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402a915-09eb-414d-b3d0-b126dff6a2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_features = title_vectorize_layer(title_input)\n",
    "title_features = layers.Embedding(size_vocabulary, 3, name = \"embedding\")(lyrics_features)\n",
    "title_features = layers.Dropout(0.2)(lyrics_features)\n",
    "title_features = layers.GlobalAveragePooling1D()(lyrics_features)\n",
    "title_features = layers.Dropout(0.2)(lyrics_features)\n",
    "title_features = layers.Dense(32, activation='relu')(title_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925dfab-2b91-4664-aadb-31e415599bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.Dense(2, name = \"fake\")(title_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65fba0-6a99-4321-9ed6-f0ffc7a60784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ca1c9-2d5f-407e-b9da-305cc51fd3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_input = keras.Input(\n",
    "    shape = (1,),\n",
    "    name = \"text\",\n",
    "    dtype = \"string\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1940c3-8c9a-4a65-8413-629aba7d5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = layers.Dense(32, activation='relu')(text_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B-3] *",
   "language": "python",
   "name": "conda-env-PIC16B-3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
